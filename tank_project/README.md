# üéÆ Tank Arena - Projet de Combat Robotique en R√©alit√© Mixte

Syst√®me de jeu robotique en temps r√©el combinant vision par ordinateur, projection augment√©e, intelligence artificielle et contr√¥le ROS. Deux robots physiques (Turtlebot Burger) s'affrontent dans une ar√®ne projet√©e : un robot contr√¥l√© par IA et un robot pilot√© par un humain.

---

## üìê Vue d'ensemble du syst√®me

### Principe g√©n√©ral

- **Ar√®ne physique** : Tapis au sol avec ArUco markers et obstacles
- **Vision** : Cam√©ra RealSense D435 en vue a√©rienne
- **Projection** : Projecteur affichant la zone de jeu, HUD, effets visuels
- **Robots** : 2x Turtlebot Burger avec marqueurs ArUco
  - Robot 4 (IA) : Contr√¥l√© par l'algorithme
  - Robot 5 (Humain) : Contr√¥l√© physiquement par le joueur
- **Communication** : ROS Bridge (WebSocket) pour envoyer commandes au robot IA

### Pipeline complet

```
RealSense Camera ‚Üí ArUco Detection ‚Üí Kalman Filtering
                         ‚Üì
                   World Model (poses + occupancy grid)
                         ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚Üì                         ‚Üì
      Game Engine              AI Strategy
    (arbitre, tirs)        (behavior tree, A*)
            ‚Üì                         ‚Üì
      Visualization ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ROS Bridge Client
    (Pygame projector)        (commandes robot IA)
```

---

## üóÇÔ∏è Architecture du projet

```
tanker_project/
‚îÇ
‚îú‚îÄ‚îÄ core/                      # Logique m√©tier (ind√©pendante vision/affichage)
‚îÇ   ‚îú‚îÄ‚îÄ game/                  # Arbitre et r√®gles de jeu
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ game_engine.py     # Boucle principale, orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py           # √âtat complet (robots, score, timer)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rules.py           # R√®gles et param√®tres de jeu
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raycast.py         # D√©tection collision tirs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ timers.py          # Cooldowns tirs, timer match
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hits.py            # Gestion impacts
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ia/                    # Intelligence artificielle
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ behavior_tree.py   # Arbre de comportement modulaire
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decisions.py       # Conditions tactiques (LOS, distance)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ strategy.py        # Combiner BT ‚Üí objectif + fire_request
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ planners/          # Path planning
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ a_star.py      # Algorithme A*
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ heuristics.py  # Fonctions heuristiques
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ path_utils.py  # Lissage, simplification trajectoires
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ world/                 # Repr√©sentation monde 2D m√©trique
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ world_model.py     # Unification : robots, obstacles, zones
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ occupancy_grid.py  # Grille d'occupation 2D (r√©solution 2cm)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inflation.py       # Dilatation obstacles (s√©curit√©)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ coordinate_frames.py  # Transformations Camera‚ÜîWorld‚ÜîPygame
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ control/               # Contr√¥le bas niveau
‚îÇ       ‚îú‚îÄ‚îÄ trajectory_follower.py  # Suivi waypoints (Pure Pursuit)
‚îÇ       ‚îú‚îÄ‚îÄ kinematics.py      # Mod√®le cin√©matique Turtlebot
‚îÇ       ‚îú‚îÄ‚îÄ motion_constraints.py  # Limites vitesse/acc√©l√©ration
‚îÇ       ‚îî‚îÄ‚îÄ ros_bridge_client.py   # Client WebSocket ‚Üí ROS
‚îÇ
‚îú‚îÄ‚îÄ perception/                # Vision et calibration
‚îÇ   ‚îú‚îÄ‚îÄ camera/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ realsense_stream.py    # Interface RealSense D435
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aruco_detector.py      # D√©tection markers ArUco
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ color_segmentation.py  # Seuillage obstacles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kalman_filter.py       # Filtrage poses (x,y,Œ∏,·∫ã,·∫è,œâ)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ homography.py          # Calculs H_C2AV, H_C2W
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ calibration/           # Phase de calibration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calibration_wizard.py  # S√©quence interactive compl√®te
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scale_estimator.py     # Estimation √©chelle m√©trique
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arena_solver.py        # Calcul dimensions ar√®ne
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ projector_mapping.py   # Transform Monde ‚Üí Projecteur
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing/
‚îÇ       ‚îú‚îÄ‚îÄ thresholding.py    # Pr√©traitement images
‚îÇ       ‚îú‚îÄ‚îÄ contours.py        # Extraction formes obstacles
‚îÇ       ‚îî‚îÄ‚îÄ image_utils.py     # Utilitaires CV
‚îÇ
‚îú‚îÄ‚îÄ visualization/             # Affichage et projection
‚îÇ   ‚îú‚îÄ‚îÄ pygame_renderer.py     # Moteur de rendu principal
‚îÇ   ‚îú‚îÄ‚îÄ projector_overlay.py   # Conversion coordonn√©es ‚Üí pixels projecteur
‚îÇ   ‚îú‚îÄ‚îÄ ui_hud.py              # HUD (timer, score, infos)
‚îÇ   ‚îú‚îÄ‚îÄ debug_draw.py          # Visualisation debug (paths, LOS, grid)
‚îÇ   ‚îî‚îÄ‚îÄ colors.py              # Palette de couleurs
‚îÇ
‚îú‚îÄ‚îÄ config/                    # Configuration YAML
‚îÇ   ‚îú‚îÄ‚îÄ arena.yaml             # Calibration, H_C2W, dimensions
‚îÇ   ‚îú‚îÄ‚îÄ camera.yaml            # Param√®tres cam√©ra, IDs ArUco
‚îÇ   ‚îú‚îÄ‚îÄ ia.yaml                # Seuils IA, distances s√©curit√©
‚îÇ   ‚îú‚îÄ‚îÄ game.yaml              # Dur√©e match, cooldowns
‚îÇ   ‚îî‚îÄ‚îÄ robot.yaml             # Dimensions robot, vitesses max
‚îÇ
‚îú‚îÄ‚îÄ scripts/                   # Points d'entr√©e
‚îÇ   ‚îú‚îÄ‚îÄ run_calibration.py     # Lancer wizard calibration
‚îÇ   ‚îú‚îÄ‚îÄ run_game.py            # Lancer partie (boucle 30 FPS)
‚îÇ   ‚îî‚îÄ‚îÄ export_debug_data.py   # Export snapshots debug
‚îÇ
‚îú‚îÄ‚îÄ assets/                    # Ressources
‚îÇ   ‚îú‚îÄ‚îÄ aruco_markers/         # Images markers haute r√©solution
‚îÇ   ‚îú‚îÄ‚îÄ fonts/                 # Polices pour HUD
‚îÇ   ‚îî‚îÄ‚îÄ images/                # Textures, ic√¥nes
‚îÇ
‚îú‚îÄ‚îÄ logs/                      # Logs centralis√©s
‚îÇ   ‚îú‚îÄ‚îÄ runtime.log
‚îÇ   ‚îú‚îÄ‚îÄ calibration.log
‚îÇ   ‚îî‚îÄ‚îÄ debug.log
‚îÇ
‚îî‚îÄ‚îÄ README.md                  # Ce fichier
```

---

## üîß Phase 1 : Calibration (one-time setup)

La calibration s'effectue **une seule fois** avant la premi√®re partie, ou quand l'ar√®ne change.

### Objectif

√âtablir la transformation **Camera ‚Üí World** (m√©trique) et cartographier les obstacles fixes.

### √âtapes du wizard

#### 1.1 D√©finition Safe Zone

**But** : D√©finir la marge de projection pour √©viter les bords du projecteur.

- Marge configur√©e : `MARGIN = 50 px`
- Zone de jeu projet√©e : `(50, 50) ‚Üí (1870, 1030)` pour projecteur 1920√ó1080

**Logs** :
```
[CALIB] MARGIN set to 50 px
[CALIB] Arena rect in projector: (50,50) -> (1870,1030)
```

#### 1.2 Calibration g√©om√©trique (H_C2AV)

**But** : Obtenir l'homographie **Camera ‚Üí Arena Virtual** (espace normalis√© [0,1]√ó[0,1]).

**Proc√©dure** :
1. Projecteur affiche 4 ArUco aux coins de l'ar√®ne (IDs 0-3)
2. Cam√©ra d√©tecte les 4 markers
3. Correspondances √©tablies :
   - ArUco 0 ‚Üí (0.0, 0.0) bottom-left
   - ArUco 1 ‚Üí (1.0, 0.0) bottom-right
   - ArUco 2 ‚Üí (1.0, 1.0) top-right
   - ArUco 3 ‚Üí (0.0, 1.0) top-left
4. Calcul homographie : `H_C2AV = cv2.findHomography(src_points, dst_points)`

**Logs** :
```
[CALIB] Step 2/4: Geometric calibration
[CALIB] Detected 4 projected corners
[CALIB] H_C2AV computed successfully
```

**Option raffinement** :
- R√©p√©ter avec plusieurs captures
- Moyenner les homographies ou utiliser RANSAC

#### 1.3 Calibration m√©trique (H_C2W)

**But** : Convertir l'espace Arena Virtual en **m√®tres r√©els**.

**Proc√©dure** :
1. Placer un ArUco physique de taille connue dans l'ar√®ne (ex: 10 cm)
2. Utilisateur entre la taille r√©elle : `marker_size_real = 0.10 m`
3. D√©tection ArUco robot (ID 4 ou 5)
4. Estimation taille en unit√©s AV :
   ```
   size_av = estimate_marker_size_av(corners, H_C2AV)
   ```
5. Calcul de l'√©chelle :
   ```
   scale = marker_size_real / size_av
   ```
6. Construction matrice de scaling :
   ```
   S = [[scale,  0,      0],
        [0,      scale,  0],
        [0,      0,      1]]
   ```
7. Homographie finale :
   ```
   H_C2W = S ¬∑ H_C2AV
   ```

**Logs** :
```
[CALIB] Real marker size: 0.10 m
[CALIB] Marker size in AV: 0.087 units
[CALIB] Scale: 1.149 m / AV_unit
[CALIB] H_C2W computed
[CALIB] Calibration OK
```

**R√©sultat** :
- Transformation compl√®te : `(u, v)` pixels cam√©ra ‚Üí `(x_W, y_W)` m√®tres monde

#### 1.4 Cartographie obstacles statiques

**But** : D√©tecter obstacles fixes et cr√©er la grille d'occupation de base.

**Proc√©dure** :
1. Projecteur affiche fond blanc uniforme
2. Placer obstacles physiques (blocs, murs)
3. Capture image cam√©ra
4. Seuillage : obstacles sombres sur fond blanc
5. Extraction contours
6. Conversion pixels ‚Üí m√®tres via `H_C2W`
7. Remplissage grille d'occupation :
   - R√©solution : `RES = 0.02 m` (2 cm)
   - Taille ar√®ne : ex. `L = 2.85 m`, `W = 1.90 m`
   - Dimensions grille : `Nx = 143, Ny = 95 cellules`
   - Valeurs : `0 = libre`, `1 = obstacle fixe`

**Logs** :
```
[CALIB] Step 4/4: Obstacle mapping
[CALIB] Arena size estimated: 2.85m x 1.90m
[CALIB] Grid resolution: 0.02m -> 143 x 95 cells
[CALIB] Static obstacles mapped
```

**Sauvegarde** : Tous les r√©sultats dans `config/arena.yaml`

---

## üéØ Phase 2 : Jeu (boucle temps r√©el 30 FPS)

Une fois calibr√©, le syst√®me entre en boucle de jeu.

### 2.1 Vision & Tracking

#### 2.1.1 Acquisition
- RealSense capture frame couleur (et optionnellement profondeur)

#### 2.1.2 D√©tection ArUco robots
- Robot IA ‚Üí **ID 4**
- Robot Humain ‚Üí **ID 5**

Pour chaque robot d√©tect√© :
- Centre marker en pixels : `(u, v)`
- Orientation : `theta_cam` (radians)

#### 2.1.3 Transformation m√©trique

Conversion pixels ‚Üí monde :
```
[x_W, y_W, 1]^T = H_C2W * [u, v, 1]^T
```

R√©sultat : `(x_W, y_W)` en m√®tres, `theta` en radians (rep√®re monde)

**Logs (exemple 1 Hz)** :
```
[VISION] Robot4 raw (px): (1023,540) -> (1.23, 0.87)m, theta=1.57 rad
[VISION] Robot5 raw (px): (856,712) -> (0.95, 1.42)m, theta=-0.52 rad
```

### 2.2 Filtrage Kalman

**But** : Stabiliser poses et estimer vitesses.

#### Mod√®le d'√©tat (pour chaque robot)

√âtat : `X = [x, y, vx, vy, Œ∏, œâ]^T`

Mod√®le discret (dt = 1/30 s) :
```
x_{k+1} = x_k + vx_k ¬∑ dt
y_{k+1} = y_k + vy_k ¬∑ dt
vx_{k+1} = vx_k
vy_{k+1} = vy_k
Œ∏_{k+1} = Œ∏_k + œâ_k ¬∑ dt
œâ_{k+1} = œâ_k
```

Mesures cam√©ra : `Z = [x_mes, y_mes, Œ∏_mes]^T`

#### Cycle Kalman
1. **Predict** : Projection √©tat √† k+1
2. **Update** : Correction avec mesure ArUco

**Avantages** :
- Positions/orientations stables
- Vecteurs vitesse pour anticipation IA

**Logs** :
```
[KALMAN] Robot4 state: x=1.21, y=0.88, vx=0.03, vy=-0.01, theta=1.60, omega=0.02
[KALMAN] Robot5 state: x=0.96, y=1.41, vx=-0.08, vy=0.05, theta=-0.50, omega=-0.10
```

### 2.3 Grille d'occupation dynamique

**Mise √† jour** :
1. Partir de la grille statique (obstacles fixes)
2. Marquer robots comme obstacles dynamiques :
   - Rayon robot : `R_robot ‚âà 0.18 m`
   - Conversion cellules : `R_cells = int(0.18 / 0.02) ‚âà 9 cellules`
3. **Inflation** : Rayon s√©curit√© additionnel
   - Rayon total : `0.24 m ‚Üí 12 cellules`
4. Costmap style ROS :
   - `0` = libre
   - `100` = obstacle
   - Valeurs interm√©diaires possibles

**Usage** : Line-of-sight IA, path planning

**Logs** :
```
[GRID] Dynamic obstacles updated (Robot4, Robot5)
[GRID] Inflated radius: 0.24m -> 12 cells
```

### 2.4 Game Engine (arbitre)

**Responsabilit√©s** : Application stricte des r√®gles, aucune d√©cision "intelligente".

#### 2.4.1 Timers & cooldowns

Variables maintenues :
- `t_game` : Temps √©coul√© depuis d√©but partie
- `next_allowed_shot_human` : Prochain tir humain autoris√©
- `next_allowed_shot_ai` : Prochain tir IA autoris√©

Exemple configuration :
- Tir humain automatique : `T_human = 5.0 s`
- Cooldown tir IA : `T_ai_cooldown = 3.0 s`

#### 2.4.2 Gestion tir humain

```
Si t_now >= next_allowed_shot_human :
    1. Calcul rayon depuis (x_H, y_H) direction theta_H
    2. Raycast (d√©tection collisions obstacles + robots)
    3. Si Robot4 touch√© ‚Üí hits_robot4 += 1
    4. next_allowed_shot_human = t_now + T_human
```

#### 2.4.3 Gestion tir IA

```
Si IA renvoie fire_request=True ET cooldown OK :
    1. Raycast depuis (x_A, y_A) direction theta_A
    2. Si Robot5 touch√© ‚Üí hits_robot5 += 1
    3. next_allowed_shot_ai = t_now + T_ai_cooldown
```

#### 2.4.4 Fin de partie

**Conditions** :
- Dur√©e √©coul√©e : `t_now >= t_start + T_match` (ex: 3 min)
- OU nombre hits atteint : `hits_robot >= H_max`

**D√©termination vainqueur** :
- Plus grand nombre de hits inflig√©s
- Ou moins de hits re√ßus

**Logs** :
```
[GAME] Human fired -> HIT Robot4
[GAME] AI fired -> MISS
[GAME] Hits: R4=2, R5=3
[GAME] Time remaining: 120s
[GAME] Match end, winner: Robot5 (HUMAN)
```

### 2.5 Intelligence Artificielle (Robot 4)

L'IA **propose** des actions, n'applique rien directement.

#### 2.5.1 Entr√©es IA

- Pose filtr√©e Robot4 : `(x_A, y_A, theta_A, vx_A, vy_A, omega_A)`
- Pose filtr√©e Robot5 : `(x_H, y_H, theta_H, vx_H, vy_H, omega_H)`
- Occupancy grid gonfl√©e (costmap)
- √âtat jeu : temps restant, hits, cooldowns

#### 2.5.2 Arbre de comportement (Behavior Tree)

**Structure exemple** :

```
Selector (priorit√©)
‚îú‚îÄ Sequence "SURVIE"
‚îÇ  ‚îú‚îÄ Condition: distance_ennemi < d_safe ?
‚îÇ  ‚îî‚îÄ Action: RETREAT (chercher cover, s'√©loigner)
‚îÇ
‚îî‚îÄ Selector "COMBAT"
   ‚îú‚îÄ Sequence "ATTAQUE"
   ‚îÇ  ‚îú‚îÄ Condition: line_of_sight claire ?
   ‚îÇ  ‚îú‚îÄ Action: maintenir distance optimale
   ‚îÇ  ‚îî‚îÄ Action: fire_request = True
   ‚îÇ
   ‚îî‚îÄ Sequence "REPOSITIONNEMENT"
      ‚îú‚îÄ Action: FLANK (contourner obstacles)
      ‚îî‚îÄ Action: chercher position tir
```

**√âtats possibles** :
- `RETREAT` : Fuite, priorit√© survie
- `ATTACK` : Ligne de vue claire, tir actif
- `FLANK` : Contournement tactique
- `SEEK_COVER` : Recherche couverture

#### 2.5.3 Path Planning

**Algorithme** : A* sur grille d'occupation

**Processus** :
1. IA d√©cide objectif : `(x_goal, y_goal)`
2. Conversion en cellule grille
3. A* calcule chemin :
   - D√©part : cellule Robot4
   - Arriv√©e : cellule proche de goal (libre)
   - Heuristique : distance euclidienne
   - Co√ªt : costmap (√©viter obstacles)
4. R√©sultat : liste waypoints `[(x_1, y_1), ..., (x_n, y_n)]` en m√®tres

**Logs** :
```
[AI] State: FLANK, target=(1.85, 1.20)
[AI] Path computed: 32 waypoints
[AI] LOS: FALSE, fire_request: FALSE
```

### 2.6 Contr√¥le & ROS Bridge

#### 2.6.1 Suivi de trajectoire

**Contr√¥leur simple** (Pure Pursuit) :

```
Waypoint actuel: (x_wp, y_wp)
Erreur position:
    dx = x_wp - x_A
    dy = y_wp - y_A
    distance = sqrt(dx¬≤ + dy¬≤)

Erreur orientation:
    theta_target = atan2(dy, dx)
    dtheta = angle_diff(theta_A, theta_target)

Commandes:
    v = k_v * distance          (vitesse lin√©aire)
    œâ = k_theta * dtheta        (vitesse angulaire)

Contraintes:
    v ‚àà [-0.22, 0.22] m/s
    œâ ‚àà [-2.84, 2.84] rad/s
```

**Cas sp√©ciaux** :
- Waypoint atteint ‚Üí passer au suivant
- Plus de waypoint ‚Üí `v=0`, orientation vers ennemi si tir

#### 2.6.2 Envoi ROS Bridge

**Format message** (WebSocket JSON) :
```json
{
  "robot_id": 4,
  "v": 0.15,
  "omega": -0.30
}
```

ROS-bridge re√ßoit ‚Üí publie sur `/cmd_vel` (Twist)

**Logs** :
```
[CTRL] Robot4 cmd: v=0.15 m/s, omega=-0.30 rad/s
[ROS] Command sent to bridge
[ROS] Latency: 12ms
```

### 2.7 Visualisation (Pygame + Projecteur)

#### 2.7.1 Transformation Monde ‚Üí Projecteur

**Param√®tres** :
- Ar√®ne m√©trique : `Lx √ó Ly` m√®tres
- Zone projet√©e : `ARENA_PX_WIDTH √ó ARENA_PX_HEIGHT` pixels
- Marge : `MARGIN` pixels

**Scale** :
```
Sx = ARENA_PX_WIDTH / Lx
Sy = ARENA_PX_HEIGHT / Ly
S = min(Sx, Sy)    # uniforme, garde aspect ratio
```

**Conversion point** :
```
Point monde: (x_W, y_W) en m√®tres

Pixels projecteur:
    Xp = MARGIN + x_W * S
    Yp = MARGIN + (Ly - y_W) * S    # y=0 en bas
```

#### 2.7.2 √âl√©ments affich√©s

**1. Fond ar√®ne**
- Rectangle zone de jeu
- Bordures, grille optionnelle

**2. Obstacles**
- Rectangles/polygones align√©s grille
- Couleur distincte (gris fonc√©)

**3. Robots**
- Cercles position `(x_W, y_W)` ‚Üí `(Xp, Yp)`
- Orientation : petit trait dans direction `theta`
- Couleurs : bleu (IA), rouge (humain)

**4. Canon virtuel**
- Ligne de vis√©e (1 m√®tre) :
  ```
  x_end = x_robot + cos(theta)
  y_end = y_robot + sin(theta)
  ```
- Conversion `(x_end, y_end)` ‚Üí pixels
- Couleur selon √©tat (blanc normal, jaune si tir imminent)

**5. Lock-on IA**
- Si IA a line-of-sight sur humain :
  - Point rouge clignotant sur Robot5
  - Indicateur "LOCKED"

**6. HUD (interface)**
- **Timer** : Temps restant (MM:SS)
- **Scores** :
  ```
  HITS IA: 3
  HITS HUMAN: 2
  ```
- **√âtat IA** : ATTACK / FLANK / RETREAT
- **Cooldowns** : Barres de progression tirs

**7. Fin de partie**
- √âcran overlay : `"WINNER: HUMAN"` ou `"WINNER: AI"`
- R√©capitulatif scores
- Option rejouer

**Logs** :
```
[VIS] Frame rendered @30fps
[VIS] LOS=TRUE, Lock-on active
[VIS] HumanHits=2, AIHits=3
```

---

## üåê Espaces de coordonn√©es

Le syst√®me utilise 4 rep√®res principaux :

### 1. Camera (C)
- Origine : Centre optique cam√©ra
- Unit√©s : **pixels**
- Coordonn√©es : `(u, v)`
- Axes : u‚Üídroite, v‚Üíbas

### 2. Arena Virtual (AV)
- Origine : Coin bas-gauche ar√®ne
- Unit√©s : **normalis√© [0, 1]**
- Coordonn√©es : `(x_av, y_av)`
- Usage : Interm√©diaire calibration

### 3. World (W)
- Origine : Coin bas-gauche ar√®ne
- Unit√©s : **m√®tres**
- Coordonn√©es : `(x_W, y_W)`
- Axes : x‚Üídroite, y‚Üíhaut, z‚Üísortant (r√®gle main droite)
- **Principal rep√®re utilis√©**

### 4. Projecteur (PROJ)
- Origine : Coin haut-gauche image projet√©e
- Unit√©s : **pixels projecteur**
- Coordonn√©es : `(Xp, Yp)`
- R√©solution : ex. 1920√ó1080

### Transformations

```
Camera ‚Üí AV:    H_C2AV  (homographie, calibration g√©om√©trique)
AV ‚Üí World:     S       (scaling m√©trique)
Camera ‚Üí World: H_C2W = S ¬∑ H_C2AV
World ‚Üí Proj:   Scaling lin√©aire + translation (margin)
```

---

## üèóÔ∏è Principes d'architecture

### ‚úÖ S√©paration des responsabilit√©s

Chaque module a un r√¥le clair :
- **Vision** : Capte et d√©tecte
- **Monde** : Repr√©sente √©tat m√©trique
- **Jeu** : Applique r√®gles
- **IA** : D√©cide strat√©gie
- **Contr√¥le** : Ex√©cute mouvements
- **Visualisation** : Affiche

### ‚úÖ Clean Architecture

- `core/` ne d√©pend **JAMAIS** de :
  - Pygame
  - Cam√©ra
  - Sockets
- `perception/` ne d√©pend **JAMAIS** de :
  - Logique jeu
  - IA
- `visualization/` ne prend **JAMAIS** de d√©cisions

### ‚úÖ Modularit√©

**Rempla√ßable facilement** :
- Changer cam√©ra (ZED, webcam) ‚Üí toucher uniquement `perception/camera/`
- Changer IA ‚Üí toucher uniquement `core/ia/`
- Changer pathfinding ‚Üí toucher uniquement `core/ia/planners/`
- Ajouter robot ‚Üí configuration, pas code

### ‚úÖ Configuration externalis√©e

**Tout ce qui peut varier ‚Üí YAML** :
- Dimensions ar√®ne
- Vitesse robots
- Seuils IA
- Dur√©e partie
- IDs ArUco

**Avantage** : Reconfigurer sans recompiler

### ‚úÖ Scalabilit√©

**Extensions futures faciles** :
- Mode 1v1v1 (3 robots)
- Nouveaux types obstacles
- Power-ups projet√©s
- Mini-map temps r√©el
- Multiples strat√©gies IA switchables
- Enregistrement replay

---

## üöÄ Utilisation

### Premi√®re utilisation : Calibration

```bash
# Activer environnement Python
pyenv activate ubuntu

# Lancer wizard calibration
python3 scripts/run_calibration.py
```

**Suivre les instructions** :
1. D√©finir safe zone
2. D√©tecter coins projet√©s (4 ArUco)
3. Placer marker physique connu (ex: 10cm)
4. Cartographier obstacles fixes

‚Üí G√©n√®re `config/arena.yaml`

### Lancer une partie

```bash
# Activer environnement
pyenv activate ubuntu

# D√©marrer ROS Bridge (terminal s√©par√©)
# roslaunch rosbridge_server rosbridge_websocket.launch

# Lancer le jeu
python3 scripts/run_game.py
```

**Boucle principale 30 FPS** :
- Vision tracking
- IA d√©cisions
- Contr√¥le robot IA
- Projection visualisation

### Debugging

```bash
# Export debug snapshot (config + grille + √©tat)
python3 scripts/export_debug_data.py

# Capture live depuis cam√©ra (requiert RealSense connect√©e)
python3 scripts/export_debug_data.py --live

# Export vers r√©pertoire sp√©cifique
python3 scripts/export_debug_data.py --output-dir ~/mon_debug

# Voir logs temps r√©el
tail -f logs/runtime.log

# Activer affichage debug (config/game.yaml)
debug_mode: true
```

**Contenu export debug** :
- `config/` : Tous les fichiers YAML de configuration
- `occupancy_grid.npy` / `.png` : Grille d'occupation (NumPy + visualisation)
- `game_state.json` : √âtat complet du jeu (poses, scores, IA)
- `manifest.json` : Index des √©l√©ments export√©s
- `camera_frame.png` / `_annotated.png` : Captures cam√©ra (mode `--live`)
- `aruco_detections.json` : D√©tections ArUco (mode `--live`)
- `depth_frame.npy` / `_viz.png` : Donn√©es profondeur (mode `--live`)
- `*.log` : Copies des fichiers logs

---

## üìä Logs & Monitoring

### Format logs

Tous les logs suivent le pattern :
```
[MODULE] Message d√©taill√©
```

**Modules** :
- `[CALIB]` : Calibration
- `[VISION]` : D√©tection ArUco
- `[KALMAN]` : Filtrage
- `[GRID]` : Grille occupation
- `[GAME]` : Arbitre
- `[AI]` : Strat√©gie IA
- `[CTRL]` : Contr√¥le
- `[ROS]` : Communication bridge
- `[VIS]` : Visualisation

### Fichiers logs

- `logs/calibration.log` : Historique calibrations
- `logs/runtime.log` : Parties jou√©es
- `logs/debug.log` : Informations d√©taill√©es debug

---

## üîß Configuration

### Fichiers cl√©s

#### `config/arena.yaml`
```yaml
projector:
  width: 1920
  height: 1080
  margin: 50

arena:
  width_m: 2.85
  height_m: 1.90

transform:
  H_C2W: [[...], [...], [...]]  # 3x3 matrix
  scale: 1.149

obstacles: [...]  # Liste obstacles fixes
```

#### `config/game.yaml`
```yaml
match_duration_s: 180
human_fire_cooldown_s: 5.0
ai_fire_cooldown_s: 3.0
max_hits: 10
fps: 30
```

#### `config/ia.yaml`
```yaml
safe_distance_m: 0.8
attack_distance_m: 1.5
retreat_threshold_m: 0.5
path_replan_interval_s: 2.0
```

---

## üìö D√©pendances

### Python (requirements.txt)

```
opencv-contrib-python>=4.8.0
pyrealsense2>=2.54.0
pygame>=2.5.0
numpy>=1.24.0
scipy>=1.11.0
pyyaml>=6.0
websocket-client>=1.6.0
```

### Syst√®me

- **ROS Noetic** (ou ROS2 Humble)
- **rosbridge_server** pour communication WebSocket
- **RealSense SDK 2.0**

### Hardware

- Intel RealSense D435 (cam√©ra RGB-D)
- Projecteur (recommand√© ‚â•1920√ó1080)
- 2√ó Turtlebot Burger avec ArUco markers
- PC Linux (Ubuntu 20.04/22.04 recommand√©)

---

## üéì Ressources techniques

### Calibration
- Zhang's camera calibration
- Homography estimation (OpenCV docs)
- ArUco marker detection

### IA
- Behavior Trees (article: "Behavior Trees for Robotics")
- A* pathfinding
- Occupancy grid navigation

### Contr√¥le
- Pure Pursuit controller
- Differential drive kinematics
- ROS navigation stack concepts

### Vision
- Kalman filtering for tracking
- Perspective transformation
- Color-based segmentation

---

## üë• Contribution

D√©velopp√© dans le cadre d'un projet de robotique mobile avec vision par ordinateur et IA temps r√©el.

**Structure respectant** :
- PEP 8 (Python style)
- Clean Architecture
- SOLID principles
- Modularit√© maximale

---

## üìù License

Projet acad√©mique - √Ä d√©finir selon contexte institutionnel.

---

## üÜò Troubleshooting

### Import Error: "attempted relative import beyond top-level package"
**Solution** : V√©rifier que imports absolus sont utilis√©s (`from core.world...` et non `from ...core.world...`)

### RuntimeError: No device connected (RealSense)
**Cause** : Cam√©ra non branch√©e ou drivers manquants  
**Solution** : 
```bash
# V√©rifier connexion
rs-enumerate-devices

# R√©installer drivers si besoin
sudo apt install librealsense2-utils
```

### WebSocket connection failed
**Cause** : ROS Bridge non lanc√©  
**Solution** :
```bash
roslaunch rosbridge_server rosbridge_websocket.launch
```

### IA path planning √©choue
**Cause** : Grid mal initialis√©e ou goal inaccessible  
**Solution** : Activer `debug_draw` pour visualiser costmap

---

**Version** : 1.0  
**Derni√®re mise √† jour** : 2025-12-06
